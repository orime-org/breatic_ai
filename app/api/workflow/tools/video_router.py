# from fastapi import APIRouter, Body
# from fastapi import File, UploadFile, Path,Form
# from fastapi.responses import JSONResponse
# from app.utils.core import get_user_id
# from app.locales.translations import get_translation

# from app.utils.file_utils import write_file_base64
# from fastapi.encoders import jsonable_encoder
# from app.common.httpx_client import httpx_client
# from typing import Mapping, Optional, Tuple, Dict, Any,Union,Sequence, List
# from app.api.workflow.tools.model.video_editor_model import VideoEditorRequest,ExportOptions,TimelineClip,MediaItem,CropArea
# import math
# from decimal import Decimal, ROUND_HALF_UP
# import logging
# import skia
# from app.api.workflow.tools.video_utils import load_video,grab_frame_for_clip_time_precise
# import re
# from app.api.workflow.tools.font_utils import load_font
# import contextlib
# import asyncio
# import av, io, os
# from app.cdn.aliyun_oss import aliyun_oss_instance
# from app.common.biz_response import BizCode
# # è¿›ç¨‹æ± ç¤ºä¾‹ï¼ˆæœ€å°‘ä¾èµ–ï¼‰
# from concurrent.futures import ProcessPoolExecutor

# video_tools_router = APIRouter(
#     prefix='/tools/videos',
#     tags=['/tools/videos']
# )

# def _parse_css_color(s: Optional[str]) -> int:
#     """æ”¯æŒ #rgb/#rrggbb/#aarrggbb ä¸ rgb()/rgba()ã€‚æœªè¯†åˆ«è¿”å›é€æ˜ã€‚"""
#     if not s:
#         return skia.ColorSetARGB(0, 0, 0, 0)
#     s = s.strip().lower()
#     m = re.match(r'rgba?\(\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)(?:\s*,\s*([\d.]+))?\s*\)', s)
#     if m:
#         r, g, b = map(int, m.group(1, 2, 3))
#         a = int(float(m.group(4)) * 255) if m.group(4) is not None else 255
#         return skia.ColorSetARGB(a, r, g, b)
#     if s.startswith('#'):
#         h = s[1:]
#         if len(h) == 3:
#             r, g, b = (int(ch * 2, 16) for ch in h)
#             return skia.ColorSetARGB(255, r, g, b)
#         if len(h) == 6:
#             r = int(h[0:2], 16); g = int(h[2:4], 16); b = int(h[4:6], 16)
#             return skia.ColorSetARGB(255, r, g, b)
#         if len(h) == 8:  # AARRGGBB
#             a = int(h[0:2], 16); r = int(h[2:4], 16); g = int(h[4:6], 16); b = int(h[6:8], 16)
#             return skia.ColorSetARGB(a, r, g, b)
#     return skia.ColorSetARGB(0, 0, 0, 0)

# def _brightness_filter(percent) -> skia.ColorFilter:
#     f = percent / 100.0
#     return skia.ColorFilters.Matrix([
#         f, 0, 0, 0, 0,
#         0, f, 0, 0, 0,
#         0, 0, f, 0, 0,
#         0, 0, 0, 1, 0,
#     ])


# def _image_from_bytes(data: bytes) -> skia.Image:
#     d = skia.Data.MakeWithoutCopy(data)
#     img = skia.Image.MakeFromEncoded(d)
#     if img is None:
#         raise ValueError("Unsupported or corrupt image data")
#     return img

# async def load_image(url: str) -> skia.Image:
#     default_headers = {"User-Agent": "skia-image-loader/1.0"}
#     response = await httpx_client.run_with_retries(
#         do_request=lambda cli: cli.get(url,headers=default_headers)
#     )
#     return _image_from_bytes(response.content)

# def parse_export_settings(options: Optional[ExportOptions] = None) -> Tuple[int, int, Dict[str, int], int, int]:
#     resolution = options.resolution if options and options.resolution else "1920x1080"
#     w_str, h_str = resolution.split("x", 1)
#     width, height = int(w_str), int(h_str)
#     if width <= 0 or height <= 0:
#         raise ValueError(f"Invalid resolution format: {resolution}")
#     canvas_size = {"width": width, "height": height}

#     fps = options.frame_rate if options and options.frame_rate else 30
#     audio_sample_rate = options.audio_sample_rate if options and options.audio_sample_rate else 44100
#     return width, height, canvas_size, fps, audio_sample_rate

# def get_base_canvas_size(canvas_ratio: str) -> Dict[str, int]:
#     match canvas_ratio:
#         case "16:9":
#             return { "width": 1920, "height": 1080 }
#         case "9:16":
#             return { "width": 1080, "height": 1920 }
#         case "1:1":
#             return { "width": 1080, "height": 1080 }
#         case _:
#             # é»˜è®¤ä½¿ç”¨ 16:9
#             return { "width": 1920, "height": 1080 }


# def get_visible_clips(clips: List[TimelineClip], current_time: float) -> List[TimelineClip]:
#     # è¿‡æ»¤ï¼šstart <= current_time < end
#     filtered = [
#         c for c in clips
#         if c.start is not None and c.end is not None
#         and current_time >= c.start and current_time < c.end
#     ]

#     # æ’åºï¼šæŒ‰ track_index é™åºï¼›None è§†ä¸º -âˆï¼ˆæ’åˆ°æœ€åï¼‰
#     return sorted(
#         filtered,
#         key=lambda c: (c.track_index if c.track_index is not None else float("-inf")),
#         reverse=True,
#     )
# def wrap_lines_skia(text: str, width: float, font: skia.Font) -> list[str]:
#     raw_lines = text.split('\n')
#     lines: list[str] = []

#     for raw in raw_lines:
#         if raw == '':
#             # ç©ºè¡Œä¹Ÿè¦ä¿ç•™
#             lines.append('')
#             continue

#         current = ''
#         for ch in raw:                         # é€â€œå­—ç¬¦â€ç´¯åŠ 
#             test = current + ch
#             w = font.measureText(test)         # ç­‰ä»·äº ctx.measureText(test).width
#             if w > width and current != '':
#                 # è¶…è¿‡å®½åº¦ï¼Œå½“å‰è¡Œç»“æŸï¼›æ–°è¡Œä»è¿™ä¸ªå­—ç¬¦å¼€å§‹
#                 lines.append(current)
#                 current = ch
#             else:
#                 current = test

#         if current != '':
#             lines.append(current)

#     return lines
# # Canvas çš„ shadowBlur åˆ° Skia çš„ sigma çš„è¿‘ä¼¼æ¢ç®—
# def blur_to_sigma(shadow_blur: float) -> float:
#     # Skia å†…éƒ¨å¸¸ç”¨çš„è¿‘ä¼¼ï¼šsigma â‰ˆ radius * 0.57735 + 0.5
#     return 0 if shadow_blur <= 0 else (shadow_blur * 0.57735 + 0.5)

# def apply_canvas_shadow(paint: skia.Paint, shadow_color: str,
#                         shadow_offset_x: float = 0.0, shadow_offset_y: float = 0.0,
#                         shadow_blur: float = 0.0):
#     if not shadow_color and shadow_blur <= 0:
#         return
#     sigma = blur_to_sigma(shadow_blur)
#     # å’Œ Canvas è¯­ä¹‰ä¸€è‡´ï¼šåœ¨åŸå›¾ä¸‹æ–¹ç”Ÿæˆä¸€å±‚åç§»+æ¨¡ç³Šçš„æœ‰è‰²é˜´å½±ï¼Œå†ä¸åŸå›¾ä¸€èµ·è¾“å‡º
#     filt = skia.ImageFilters.DropShadow(
#         dx=shadow_offset_x, dy=shadow_offset_y,
#         sigmaX=sigma, sigmaY=sigma,
#         color=_parse_css_color(shadow_color),
#         input=None
#     )
#     paint.setImageFilter(filt)

# def compute_draw_x(text_align: str, container_w: float, line: str, font: skia.Font) -> float:
#     ta = (text_align or "center").lower()
#     if ta == "left":
#         return -container_w / 2.0
#     w = font.measureText(line)
#     if ta == "right":
#         return container_w / 2.0 - w
#     return -w / 2.0

# async def render_single_text_clip(ctx,font,rotation,scale,opacity,clip: TimelineClip,canvas_size: Dict[str, int]):
#     text_style =   clip.text_style if clip.text_style else {}
#     text = clip.text if clip.text else "Text"
#     if text_style.text_transform:
#         if text_style.text_transform == 'uppercase':
#             text = text.upper()
#         elif text_style.text_transform == 'lowercase':
#             text = text.lower()
#         elif text_style.text_transform == 'capitalize':
#             text = re.sub(r'\b\w', lambda m: m.group(0).upper(), text, flags=re.ASCII)
    
#     width =  clip.width if clip.width else 120;
#     height = clip.height if clip.height else 40;

#     # è®¡ç®—å…ƒç´ ä¸­å¿ƒç‚¹åæ ‡ï¼ˆä»å·¦ä¸Šè§’åæ ‡è½¬æ¢ï¼‰
#     x = clip.x if clip.x else (canvas_size["width"] - width) / 2
#     y = clip.y if clip.y else (canvas_size["height"] - height) / 2
#     center_X = x + width / 2
#     center_Y = y + height / 2

#     # åº”ç”¨å˜æ¢ï¼ˆå¹³ç§»åˆ°ä¸­å¿ƒç‚¹ã€æ—‹è½¬ã€ç¼©æ”¾ï¼‰- å¯¹åº”å¤–å±‚å®¹å™¨çš„ transform
#     ctx.translate(center_X, center_Y)         # å¹³ç§»åˆ°ä¸­å¿ƒ
#     ctx.rotate(rotation)      # è§’åº¦åˆ¶
#     ctx.scale(scale, scale)

#     font_size = text_style.font_size if text_style.font_size else 48
    
#     # è®¾å®šå¡«å……è‰²

#     font_color = text_style.color if text_style.color else "#ffffff";
#     fill_paint = skia.Paint(AntiAlias=True)
#     fill_paint.setColor(_parse_css_color(font_color))

#     # é˜´å½±å‚æ•°
#     shadow_color   = text_style.shadow_color if text_style.shadow_color else None
#     shadow_offset_x = text_style.shadow_offset_x if text_style.shadow_offset_x else 0
#     shadow_offset_y = text_style.shadow_offset_y if text_style.shadow_offset_y else 0
#     shadow_blur    = text_style.shadow_blur if text_style.shadow_blur else 0
#     apply_canvas_shadow(fill_paint, shadow_color, shadow_offset_x, shadow_offset_y, shadow_blur)

#     # å¯¹é½
#     text_align = text_style.text_align if text_style.text_align else 'center'

#     # top â†’ baseline çš„æ¢ç®—ï¼ˆSkia ä»¥åŸºçº¿ä½œ yï¼‰
#     metrics = font.getMetrics()           # ascent<0, descent>0
#     ascent = metrics.fAscent              # è´Ÿæ•°
    
#     # raw_lines = text.split('\n')
#     lines: list[str] = wrap_lines_skia(text=text,width=width,font=font)


#     # è¡Œé«˜ä¸ºå­—å·çš„1.6å€
#     line_height = font_size * 1.6
    
#     total_text_height = len(lines) * line_height
#     # å‚ç›´å±…ä¸­
#     start_y_top = -total_text_height / 2

#     stroke_paint = None
#     stroke_color = text_style.stroke_color if text_style.stroke_color else None
#     stroke_width = text_style.stroke_width if text_style.stroke_width else 0
#     if stroke_color and stroke_width > 0:
#         stroke_paint = skia.Paint(AntiAlias=True, Style=skia.Paint.kStroke_Style)
#         stroke_paint.setColor(_parse_css_color(stroke_color))
#         stroke_paint.setStrokeWidth(float(stroke_width) * 2.0)  # Canvas æè¾¹å±…ä¸­ â†’ ä¹˜2
#         stroke_paint.setStrokeJoin(skia.Paint.kRound_Join)
#         stroke_paint.setStrokeMiter(2)
#         apply_canvas_shadow(stroke_paint, shadow_color, shadow_offset_x, shadow_offset_y, shadow_blur)
    
#      # è£…é¥°çº¿
#     text_decoration = (text_style.text_decoration or 'none').strip().lower()
#     decorations = [d for d in text_decoration.split(' ') if d and d != 'none']
#     deco_line_width = max(1.5, font_size * 0.06)

#     # åº”ç”¨é€æ˜åº¦
#     # ctx.globalAlpha = opacity
#     # globalAlphaï¼šç”¨å›¾å±‚ä¸€æ¬¡æ€§åº”ç”¨
#     alpha_layer = skia.Paint()
#     alpha_layer.setAlphaf(max(0.0, min(1.0, opacity)))
#     ctx.saveLayer(paint=alpha_layer)

#     try:
#         for i, line in enumerate(lines):
#             y_top  = start_y_top + i * line_height
#             y_base = y_top - ascent
#             x_left = compute_draw_x(text_align, width, line, font)
#             # å…ˆæè¾¹
#             if stroke_paint is not None:
#                 ctx.drawString(line, x_left, y_base, font, stroke_paint)
#             # å†å¡«å……
#             ctx.drawString(line, x_left, y_base, font, fill_paint)

#              # è£…é¥°çº¿ï¼ˆä¸åŠ é˜´å½±ï¼Œè·Ÿä½  JS çš„ ctx.shadow ç½®é€æ˜ä¸€è‡´ï¼‰
#             if decorations:
#                 text_w = font.measureText(line)

#                 line_paint = skia.Paint(AntiAlias=True, Style=skia.Paint.kStroke_Style)
#                 # æœ‰æè¾¹åˆ™ç”¨æè¾¹è‰²ï¼›å¦åˆ™ç”¨æ–‡å­—è‰²
#                 line_color = stroke_color if stroke_color and stroke_width > 0 else font_color
#                 line_paint.setColor(_parse_css_color(line_color))
#                 line_paint.setStrokeWidth(deco_line_width)

#                 for d in decorations:
#                     if d == 'underline':
#                         # ä½ çš„ JSï¼šcurrentY + fontSize * 0.85
#                         y_line = y_top + font_size * 0.85
#                     elif d == 'line-through':
#                         # ä½ çš„ JSï¼šcurrentY + fontSize * 0.5
#                         y_line = y_top + font_size * 0.5
#                     elif d == 'overline':
#                         # ä½ çš„ JSï¼šcurrentY - fontSize * 0.15
#                         y_line = y_top - font_size * 0.15
#                     else:
#                         continue
#                     ctx.drawLine(x_left, y_line, x_left + text_w, y_line, line_paint)
#     finally:
#         ctx.restore()

# async def render_single_image_clip(ctx,img,rotation,scale,opacity, clip: TimelineClip,media: MediaItem,canvas_size: Dict[str, int]):

#     width =  clip.width if clip.width else img.width()
#     height = clip.height if clip.height else img.height()
#     crop_area = clip.crop_area
#     # è®¡ç®—å…ƒç´ å·¦ä¸Šè§’åæ ‡å’Œä¸­å¿ƒç‚¹åæ ‡
#     x = clip.x if clip.x  is not None else (canvas_size["width"] - width) / 2
#     y = clip.y if clip.y  is not None else (canvas_size["height"] - height) / 2
#     center_X = x + width / 2
#     center_Y = y + height / 2

#     # åº”ç”¨å˜æ¢ï¼ˆå¹³ç§»åˆ°ä¸­å¿ƒç‚¹ã€æ—‹è½¬ã€ç¼©æ”¾ï¼‰- å¯¹åº”å¤–å±‚å®¹å™¨çš„ transform
#     ctx.translate(center_X, center_Y)         # å¹³ç§»åˆ°ä¸­å¿ƒ
#     ctx.rotate(rotation)      # è§’åº¦åˆ¶
#     ctx.scale(scale, scale)

#     """
#     å¤åˆ»å‰ç«¯é€»è¾‘ï¼š
#       1) é˜´å½±ï¼ˆé€šè¿‡ç»˜åˆ¶å½¢çŠ¶ï¼Œåªç”»é˜´å½±ï¼‰
#       2) åœ†è§’è£å‰ª
#       3) é€æ˜åº¦ä¸æ»¤é•œï¼ˆblur/brightnessï¼‰
#       4) ç»˜åˆ¶å›¾ç‰‡ï¼ˆå¯é€‰è£å‰ªï¼Œç›®æ ‡çŸ©å½¢å±…ä¸­ï¼‰
#       5) è½®å»“æè¾¹ï¼ˆä¸å—æ»¤é•œå½±å“ï¼‰
#     çº¦å®šï¼šå½“å‰åæ ‡åŸç‚¹å·²åœ¨å…ƒç´ ä¸­å¿ƒï¼Œæ—‹è½¬/ç¼©æ”¾å·²åœ¨å¤–å±‚åšå®Œã€‚
#     """
#     media_style = clip.media_style if clip.media_style else {}

#     rect_dst = skia.Rect.MakeXYWH(-width/2.0, -height/2.0, width, height)
   

#     # ---- è¯»å–æ ·å¼ ----
#     shadow_color_s =  media_style.shadow_color if media_style and media_style.shadow_color else None
#     shadow_blur    =  media_style.shadow_blur if media_style and media_style.shadow_blur else 0
#     shadow_dx      =  media_style.shadow_offset_x if media_style and media_style.shadow_offset_x else 0
#     shadow_dy      =  media_style.shadow_offset_y if media_style and media_style.shadow_offset_y else 0
#     border_radius  =  media_style.border_radius if media_style and media_style.border_radius else 0

#     blur_px = media_style.blur if  media_style and media_style.blur else 0
#     brightness_pct = media_style.brightness if  media_style and media_style.brightness else 100
    
#     # brightness_pct = float(media_style.get('brightness', default=100) or 100)

#     outline_color_s =  media_style.outline_color if media_style and media_style.outline_color else '#000000'
#     outline_width   =  media_style.outline_width if media_style and media_style.outline_width else 0

#     # ---- 1) é˜´å½±ï¼šåªç”»é˜´å½±ï¼Œä¸ç”»å®ä½“ ----
#     if shadow_color_s and shadow_blur > 0:
#         path = skia.Path()
#         if border_radius > 0:
#             r = min(border_radius, width/2.0, height/2.0)
#             path.addRRect(skia.RRect.MakeRectXY(rect_dst, r, r))
#         else:
#             path.addRect(rect_dst)

#         sigma = shadow_blur  # å¦‚éœ€æ›´è´´è¿‘ Canvasï¼Œå¯è®¾ sigma = shadow_blur * 0.55
#         sp = skia.Paint()
#         sp.setImageFilter(
#             skia.ImageFilters.DropShadowOnly(
#                 shadow_dx, shadow_dy, sigma, sigma, _parse_css_color(shadow_color_s)
#             )
#         )
#         ctx.drawPath(path, sp)

#     # ---- 2) åœ†è§’è£å‰ªï¼ˆå¯é€‰ï¼‰ ----
#     did_clip = False
#     if border_radius > 0:
#         r = min(border_radius, width/2.0, height/2.0)
#         # ctx.save()
#         did_clip = True
#         ctx.clipRRect(skia.RRect.MakeRectXY(rect_dst, r, r), doAA=True)

#     # ---- 3) é€æ˜åº¦ + æ»¤é•œï¼ˆå¯¹åç»­å›¾ç‰‡ç”Ÿæ•ˆï¼‰ ----
#     alpha_layer = skia.Paint()
#     alpha_layer.setAlphaf(max(0.0, min(1.0, opacity)))
#     ctx.saveLayer(paint=alpha_layer)

#     img_paint = skia.Paint(AntiAlias=True)
#     if blur_px > 0:
#         sigma = blur_px  # å¯è°ƒ 0.55 ç³»æ•°
#         img_paint.setImageFilter(skia.ImageFilters.Blur(sigma, sigma))
#     if brightness_pct != 100:
#         img_paint.setColorFilter(_brightness_filter(brightness_pct))

#     sampling = skia.SamplingOptions(skia.FilterMode.kLinear)

#     # ---- 4) ç»˜åˆ¶å›¾ç‰‡ï¼ˆæ”¯æŒè£å‰ªï¼‰ ----
    
#     if crop_area and media.width and media.height:
#         actual_w = img.width() if img.width() else media.width
#         actual_h = img.height() if img.height() else media.height
#         mw, mh = media.width, media.height
#         scale_x = actual_w / mw  
#         scale_y = actual_h / mh
        
#         cx =  crop_area.x * scale_x
#         cy =  crop_area.y * scale_y
#         cw =  crop_area.width * scale_x
#         ch =  crop_area.height * scale_y

#         src = skia.Rect.MakeXYWH(cx, cy, cw, ch)
#         ctx.drawImageRect(img, src, rect_dst, sampling, paint=img_paint)
#     else:
#         # æ— è£å‰ªï¼šç›´æ¥ç­‰æ¯”æ‹‰ä¼¸åˆ°ç›®æ ‡çŸ©å½¢
#         ctx.drawImageRect(img, rect_dst, sampling, paint=img_paint)
    
#     ctx.restore()

#     # ---- 5) è½®å»“æè¾¹ï¼ˆä¸å—æ»¤é•œå½±å“ï¼‰ ----
#     if outline_color_s and outline_width > 0:
#         stroke = skia.Paint(
#             AntiAlias=True,
#             Style=skia.Paint.kStroke_Style,
#             StrokeWidth=outline_width,
#             Color=_parse_css_color(outline_color_s),
#         )
#         if border_radius > 0:
#             r = min(border_radius, width/2.0, height/2.0)
#             ctx.drawRRect(skia.RRect.MakeRectXY(rect_dst, r, r), stroke)
#         else:
#             ctx.drawRect(rect_dst, stroke)

   


# async def render_frame(
#     ctx: skia.Canvas,
#     clips: List[TimelineClip],
#     media_items: List[MediaItem],
#     current_time,
#     canvas_size,
#     canvas_ratio,
#     image_cache: Dict[str, Any] = {},
#     video_cache: Dict[str, Any] = {},
#     text_cache: Dict[str, Any] = {},
# ) -> None:
#     base_size = get_base_canvas_size(canvas_ratio)
#     base_Width, base_height = base_size["width"], base_size["height"]
    
#     # æ¸…ç©ºç”»å¸ƒèƒŒæ™¯ï¼ˆ#000000ï¼‰
#     paint_bg = skia.Paint(AntiAlias=True, Color=skia.ColorBLACK)
#     ctx.drawRect(skia.Rect.MakeWH(canvas_size["width"], canvas_size["height"]), paint_bg)

#     ctx.save()
#     try:
#         # ç­‰æ¯”ä¾‹ç¼©æ”¾ï¼ˆä»¥å®½åº¦ä¸ºåŸºå‡†ï¼‰
#         scale = canvas_size["width"] / float(base_Width)
#         ctx.scale(scale, scale)
    
#         visible_clips: List[TimelineClip] = get_visible_clips(clips, current_time)
#         media_by_id = {m.id: m for m in media_items}
#         for clip in visible_clips: 
#             media = media_by_id.get(clip.media_id,None)
#             if not media or media.type == 'audio':
#                 continue
#             ctx.save()
#             rotation = math.radians( clip.rotation if clip.rotation else 0 )
#             scale =  clip.scale if clip.scale else 1
#             opacity = (   clip.opacity if clip.opacity else 100) / 100
#             try:
#                 if media.type == "image" and media.url:
#                     img = image_cache.get(media.url,None)
#                     if not img:
#                         img = await load_image(media.url)
#                         image_cache[media.url] = img
#                     await render_single_image_clip(ctx=ctx,img=img,rotation=rotation,scale=scale,opacity=opacity,clip=clip,media=media,canvas_size=canvas_size)
#                 elif media.type == "video" and media.url:
#                     video = video_cache.get(media.url,None)
#                     if not video:
#                         video = load_video(media.url)
#                         video_cache[media.url] = video
#                     trim_start = clip.trim_start if clip.trim_start else 0
#                     img = grab_frame_for_clip_time_precise(vr=video, current_time=current_time, clip_start=clip.start, trim_start=trim_start)
#                     await render_single_image_clip(ctx=ctx,img=img,rotation=rotation,scale=scale,opacity=opacity,clip=clip,media=media,canvas_size=canvas_size)
#                 elif media.type == "text":
#                     text_style =   clip.text_style 
#                     # åŠ è½½å­—ä½“
#                     font_size = text_style.font_size if text_style.font_size else 48
#                     font_family = text_style.font_family if text_style.font_family else "Arial"
#                     font = text_cache.get(font_family+"_"+str(font_size))
#                     if not font:

#                         font = load_font(font_size=font_size, font_family=font_family)
#                         text_cache[font_family+"_"+str(font_size)] = font
                    
#                     await render_single_text_clip(ctx=ctx,font=font,rotation=rotation,scale=scale,opacity=opacity,clip=clip,canvas_size=canvas_size)
#             finally:
#                 ctx.restore()
#     finally:
#         ctx.restore()

# def calculate_bitrate(bpp,total_pixels,fps, codec_efficiency = 1.0) -> str:
#     # åŸºç¡€ç ç‡ = åƒç´ æ•° Ã— å¸§ç‡ Ã— BPP
#     bitrate_kbps = (total_pixels * fps * bpp) / 1000; # è½¬æ¢ä¸º Kbps
#     # æ ¹æ®ç¼–ç å™¨æ•ˆç‡è°ƒæ•´
#     bitrate_kbps = bitrate_kbps * codec_efficiency
#     # è®¾ç½®æœ€å°å’Œæœ€å¤§ç ç‡
#     minBitrate = 500 # æœ€å° 500 Kbps
#     maxBitrate = 100_000     # æœ€å¤§ 100 Mbps
#     bitrate_kbps = max(minBitrate, min(maxBitrate, bitrate_kbps))
#     # è½¬æ¢ä¸º Mbpsï¼ˆä¿ç•™å°æ•°ç‚¹å1ä½ï¼‰
#     # const bitrateMbps = Math.round(bitrateKbps / 100) / 10;
#     bitrate_mbps = (Decimal(bitrate_kbps) / Decimal(1000)).quantize(Decimal("0.1"), rounding=ROUND_HALF_UP)
#     return f"{bitrate_mbps}M"


# def get_codec_efficiency(options: Optional[ExportOptions] = None):
#     codec_type = options.codec if options and options.codec else "libx264"
#     if codec_type in ["libx265", "libx265_alpha", "libx265_422"]:
#         return 0.6 # H.265 æ•ˆç‡é«˜çº¦ 40%ï¼Œæ‰€ä»¥éœ€è¦æ›´ä½ç ç‡
#     elif codec_type == "libaom-av1":
#         return 0.5 # AV1 æ•ˆç‡æ›´é«˜çº¦ 50%
#     return 1.0 # H.264 åŸºå‡†

# async def ffmeg_subprocess_exec(args):
#     return await asyncio.create_subprocess_exec(
#         *args,
#         stdin=asyncio.subprocess.PIPE,
#         stdout=asyncio.subprocess.PIPE,
#         stderr=asyncio.subprocess.PIPE,
#     )
# def build_audio_filter(i, clip, trim_start, trim_end, speed=1.0, volume=1.0):
#     # èµ·å§‹ï¼šé€‰æ‹©ç¬¬ i+1 ä¸ªè¾“å…¥çš„éŸ³é¢‘æµ
#     audio_filter = f"[{i + 1}:a]"

#     # 1) è£å‰ª + æ ¡æ­£æ—¶é—´æˆ³
#     audio_filter += f"atrim={trim_start:.3f}:{trim_end:.3f},asetpts=PTS-STARTPTS"

#     # 2) è°ƒé€Ÿï¼ˆæ³¨æ„ï¼šFFmpeg çš„ atempo æ¯æ®µå¿…é¡»åœ¨ 0.5~2.0 ä¹‹é—´ï¼›è¶…å‡ºèŒƒå›´éœ€è¦åˆ†æ®µä¸²è”ï¼‰
#     if speed != 1.0:
#         if speed <= 0:
#             raise ValueError("speed å¿…é¡»å¤§äº 0")
#         s = float(speed)
#         # æŠŠæ€»å€é€Ÿæ‹†æˆè‹¥å¹²ä¸ª 0.5~2.0 çš„å› å­
#         while s > 2.0:
#             audio_filter += ",atempo=2.0"
#             s /= 2.0
#         while s < 0.5:
#             audio_filter += ",atempo=0.5"
#             s /= 0.5
#         if abs(s - 1.0) > 1e-6:
#             audio_filter += f",atempo={s:.3f}"

#     # 3) éŸ³é‡
#     if volume != 1.0:
#         audio_filter += f",volume={volume:.3f}"

#     # 4) å»¶è¿Ÿåˆ°æ­£ç¡®æ—¶é—´ç‚¹ï¼ˆæ¯«ç§’ï¼‰ï¼›ä¸‹é¢å†™æ³•ç­‰ä»·äºä½  JS çš„ "x|x"ï¼ˆåŒå£°é“ï¼‰
#     if getattr(clip, "start", 0) > 0:
#         delay_ms = int(round(clip.start * 1000))
#         audio_filter += f",adelay={delay_ms}|{delay_ms}"
#         # ä¹Ÿå¯ç”¨å¯¹æ‰€æœ‰å£°é“ç»Ÿä¸€å»¶è¿Ÿçš„å†™æ³•ï¼ˆæ›´ç®€æ´ï¼‰ï¼š
#         # audio_filter += f",adelay={delay_ms}:all=1"

#     # è¾“å‡ºæ‰“ä¸Šæ ‡ç­¾ï¼Œä¾›åç»­å¼•ç”¨
#     audio_filter += f"[a{i}]"
#     return audio_filter

# PROCESS_POOL = ProcessPoolExecutor(max_workers=os.cpu_count())

# @video_tools_router.post("/export")
# async def export(video_editor_request: VideoEditorRequest = Body(...)):
#     loop = asyncio.get_running_loop()
#     result = await loop.run_in_executor(PROCESS_POOL, sync_export_func, video_editor_request.model_dump(mode="python"))
#     return result

# def sync_export_func(serialized_request: dict) -> str:
#     """ç»™ ProcessPoolExecutor ç”¨çš„åŒæ­¥å…¥å£â€”â€”åœ¨å­è¿›ç¨‹é‡Œå¼€ event loop è·‘å¼‚æ­¥æµç¨‹"""
#     req = VideoEditorRequest.model_validate(serialized_request)   # â† å…³é”®
#     return asyncio.run(export_async(req))

# # @video_tools_router.post('/export')
# async def export_async(video_editor_request: dict):
#     """
#     å¯¼å‡ºè§†é¢‘
#     Args:
#         video_editor_request (VideoEditorRequest): è§†é¢‘ç¼–è¾‘è¯·æ±‚å‚æ•°
#     Returns:
#         JSONResponse: åŒ…å«å¯¼å‡ºè§†é¢‘ä»»åŠ¡IDçš„JSONå“åº”
#     """
#     options: ExportOptions = video_editor_request.export_options
#     clips = video_editor_request.clips
#     canvas_ratio = video_editor_request.canvas_ratio
#     media_items = video_editor_request.media_items

#     width, height, canvas_size, fps, audio_sample_rate = parse_export_settings(options)

#     total_pixels = width * height
#     # bitrate = "5M"
#     bitrate_option = options.bitrate if options and options.bitrate else "recommended"
#     codec_efficiency = get_codec_efficiency(options)
    
#     if bitrate_option == "lower" :
#        # ä½è´¨é‡: 0.07 BPPï¼ˆé€‚åˆå¿«é€Ÿé¢„è§ˆã€ç¤¾äº¤åª’ä½“ï¼‰
#        bitrate = calculate_bitrate(bpp=0.07, total_pixels=total_pixels, fps=fps, codec_efficiency=codec_efficiency)
#     elif bitrate_option == "recommended" :
#        # æ¨èè´¨é‡: 0.12 BPPï¼ˆYouTube/Bilibili æ ‡å‡†ï¼‰
#        bitrate = calculate_bitrate(bpp=0.12, total_pixels=total_pixels, fps=fps, codec_efficiency=codec_efficiency)
#     elif bitrate_option == "higher" :
#        # é«˜è´¨é‡: 0.20 BPPï¼ˆé«˜å“è´¨å½’æ¡£ã€ä¸“ä¸šç”¨é€”ï¼‰
#        bitrate = calculate_bitrate(bpp=0.20, total_pixels=total_pixels, fps=fps, codec_efficiency=codec_efficiency)
#     else:
#        # ä½¿ç”¨è‡ªå®šä¹‰ç ç‡
#        bitrate = bitrate_option
    

#     # å¤„ç†ç¼–ç å™¨
#     codec = options.codec if options and options.codec else "libx264"
#     pixel_format = "yuv420p"

#     if (codec == "libx265_alpha"):
#         codec = "libx265"
#         pixel_format = "yuva420p"
#     elif codec == "libx265_422" :
#         codec = "libx265"
#         pixel_format = "yuv422p"

#     # å¤„ç†éŸ³é¢‘è´¨é‡
#     audio_quality = options.audio_quality if options and options.audio_quality else "aac_192"
#     audio_codec = "aac"
#     audio_bitrate = "192k"

#     if audio_quality == "aac_192":
#         audio_codec = "aac"
#         audio_bitrate = "192k"
#     elif audio_quality == "aac_256":
#         audio_codec = "aac"
#         audio_bitrate = "256k"
#     elif audio_quality == "aac_320":
#         audio_codec = "aac"
#         audio_bitrate = "320k"
#     elif audio_quality == "pcm":
#         audio_codec = "pcm_s16le"
#         audio_bitrate = "" # PCM ä¸éœ€è¦ç ç‡å‚æ•°
    
#     duration = max([c.end for c in clips]) if clips else 10

#     output_format = options.format if options and options.format else "MP4"

#     output_file = f"output.{output_format.lower()}"
    
#     # === åˆ›å»ºâ€œç”»å¸ƒâ€å¹¶è·å– Canvasï¼ˆç­‰ä»· document.createElement + getContext("2d", { alpha: true })ï¼‰===
#     info = skia.ImageInfo.Make(
#         canvas_size["width"], canvas_size["height"],
#         skia.ColorType.kBGRA_8888_ColorType,     # RGBA
#         skia.AlphaType.kPremul_AlphaType,         # alpha: trueï¼ˆé¢„ä¹˜ï¼‰
#     )
#     surface = skia.Surface.MakeRaster(info)
#     ctx = surface.getCanvas()
#     if ctx is None:
#         raise RuntimeError("æ— æ³•åˆ›å»º canvas ä¸Šä¸‹æ–‡")
#     # === å¯ç”¨å›¾åƒæŠ—é”¯é½¿/é«˜è´¨é‡å¹³æ»‘ï¼ˆSkia æ²¡æœ‰å…¨å±€å¼€å…³ï¼Œåç»­ç»˜åˆ¶æ—¶ä¼ è¿™äº›å‚æ•°ï¼‰===
#     # ç”¨äºä½å›¾é‡‡æ ·ï¼ˆç­‰ä»· imageSmoothingEnabled/Quality = 'high'ï¼‰
#     IMAGE_SAMPLING = skia.SamplingOptions(
#         skia.FilterMode.kLinear,  # çº¿æ€§è¿‡æ»¤
#         skia.MipmapMode.kLinear   # mipmapï¼Œç¼©å°æ—¶æ›´å¹²å‡€
#     )
#     # === è®¡ç®—æ€»å¸§æ•°ï¼ˆç­‰ä»· Math.ceil(duration * fps)ï¼‰===
#     total_frames = math.ceil(duration * fps)
#     logging.info(f"ğŸ“¹ æ€»å¸§æ•°: {total_frames}, å¸§ç‡: {fps}, åˆ†è¾¨ç‡: {canvas_size['width']}x{canvas_size['height']}")
   
#     audio_clips = []
#     media_by_id = {m.id: m for m in media_items}
#     # å¤„ç†éŸ³é¢‘: 55% -> 60%
#     for clip in clips:
#         media = media_by_id.get(clip.media_id,None)
#         if media and (media.type == 'audio' or media.type == 'video'):
#             audio_clips.append(clip)

#     ffmpegArgs = [
#         "ffmpeg","-y",
#         "-f","rawvideo","-pix_fmt","bgra","-s",f"{width}x{height}","-r",f"{fps}",
#         "-i","-",
#     ]
#     audio_filter_complex_parts = []
#     for i, clip in enumerate(audio_clips):
#         #   m = mediaItems.find(item => item.id === clip.mediaId);
#         audio_media = next((item for item in media_items if item.id == clip.media_id), None)
#         if not audio_media: 
#             continue
#         ffmpegArgs += ["-reconnect","1","-reconnect_streamed","1","-reconnect_at_eof","1",
#              "-thread_queue_size","8192","-i", audio_media.url]

#         # æ„å»ºéŸ³é¢‘æ»¤é•œ
#         trim_start = clip.trim_start if clip.trim_start else 0
#         audio_duration = audio_media.duration if audio_media.duration else duration

#         trim_end = clip.trim_end if clip.trim_end else audio_duration
#         volume = (clip.volume if clip.volume else 100) / 100
#         speed = clip.speed if clip.speed else 1
#         audio_filter = build_audio_filter(i=i, clip=clip,trim_start=trim_start,trim_end=trim_end,speed=speed,volume=volume)
#         audio_filter_complex_parts.append(audio_filter)

#     if len(audio_filter_complex_parts) > 0:
#         if len(audio_filter_complex_parts) == 1:
#             ffmpegArgs += ['-filter_complex', audio_filter_complex_parts[0],
#             '-map', '0:v', '-map', '[a0]',
#             '-c:a', audio_codec]
#         else:
#             mix_inputs = "".join(f"[a{i}]" for i, _ in enumerate(audio_filter_complex_parts))
#             filter_complex =";".join(audio_filter_complex_parts) + f";{mix_inputs}amix=inputs={len(audio_filter_complex_parts)}:duration=longest[aout]"
            
#             ffmpegArgs += [
#                 '-filter_complex', filter_complex,
#                 '-map', '0:v', '-map', '[aout]',
#                 '-c:a', audio_codec
#             ]
#         # æ·»åŠ éŸ³é¢‘é‡‡æ ·ç‡
#         ffmpegArgs += ['-ar', str(audio_sample_rate)]

#         # å¦‚æœä¸æ˜¯ PCMï¼Œæ·»åŠ éŸ³é¢‘ç ç‡
#         if audio_bitrate:
#             ffmpegArgs += ['-b:a', audio_bitrate]
            
#     ffmpegArgs += [
#         "-c:v", codec,
#         "-preset", "fast",
#         "-b:v", bitrate,
#         "-pix_fmt",pixel_format,
#         "-t", str(duration),
#         output_file
#     ]
#     abs_path = None
#     try:
#         proc = await ffmeg_subprocess_exec(ffmpegArgs)
#         row_bytes = info.minRowBytes()
#         buf = bytearray(row_bytes * height)
#         stderr_task = asyncio.create_task(proc.stderr.read())
#         image_cache = {}
#         video_cache = {}
#         text_cache = {}
#         # æ¸²æŸ“å¸§
#         for i in range(total_frames):
#             time = i / fps
#             await render_frame(ctx=ctx,clips= clips,media_items=media_items,current_time=time, canvas_size=canvas_size,canvas_ratio=canvas_ratio,image_cache=image_cache,video_cache=video_cache,text_cache=text_cache)
    
#             img = surface.makeImageSnapshot()
#             ok = img.readPixels(info, memoryview(buf), row_bytes, 0, 0)
#             if ok:
#                 try:
#                     proc.stdin.write(buf)
#                     # é¿å…ç®¡é“å µå¡ï¼ˆå°¤å…¶åœ¨ Windowsï¼‰
#                     await proc.stdin.drain()
#                 except (BrokenPipeError, ConnectionResetError):
#                     # FFmpeg å·²å…³é—­ stdin â€” é€šå¸¸æ˜¯å®ƒå·²æŠ¥é”™æˆ–ç»“æŸ
#                     # err = await proc
#                     rc = await proc.wait()
#                     err = (await stderr_task).decode("utf-8","ignore")
#                     raise RuntimeError(f"FFmpeg closed stdin early (rc={rc}).\n{err}") from None
     
#         # 4) ç»“æŸè¾“å…¥å¹¶ç­‰å¾… ffmpeg
#         proc.stdin.close()
#         await proc.wait()
        
#         if proc.returncode != 0:
#             err = (await proc.stderr.read()).decode("utf-8", "ignore")
#             print(f"ffmpeg å¤±è´¥ï¼š{err}")
#         abs_path = os.path.abspath(output_file)
#         oss_result = await aliyun_oss_instance.upload_file_from_local(extension=os.path.splitext(abs_path)[1].lower(),prefix="export",local_path=abs_path)
#         status = oss_result["status"]
#         if status != "success":
#             return JSONResponse(content={
#                 "code": BizCode.OSS_UPLOAD_FAILED.code,
#                 "data": "",
#                 "msg": BizCode.OSS_UPLOAD_FAILED.msg,
#             })
#         return JSONResponse(content={
#             "code": 0,
#             "data": jsonable_encoder(oss_result["resource_url"]),
#             "msg": "",
#         })
#     except Exception:
#         # å¼‚å¸¸æ—¶ç¡®ä¿ ffmpeg è¢«å›æ”¶
#         with contextlib.suppress(Exception):
#             if proc.stdin and not proc.stdin.is_closing():
#                 proc.stdin.close()
#         with contextlib.suppress(Exception):
#             await proc.wait()
#         raise
#     finally:
#         if abs_path and os.path.exists(abs_path):
#             os.remove(abs_path)